{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffee57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5cb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDetectionTrainer:\n",
    "    def __init__(self, data_dir, img_size=(224, 224)):\n",
    "        \"\"\"\n",
    "        Initialize the trainer\n",
    "        data_dir should have structure:\n",
    "        data_dir/\n",
    "            train/\n",
    "                with_mask/\n",
    "                without_mask/\n",
    "            validation/\n",
    "                with_mask/\n",
    "                without_mask/\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.img_size = img_size\n",
    "        self.model = None\n",
    "        \n",
    "    def create_model(self):\n",
    "        \"\"\"Create model using MobileNetV2 as base\"\"\"\n",
    "        base_model = MobileNetV2(\n",
    "            input_shape=(*self.img_size, 3),\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        model = keras.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(2, activation='softmax')  # 2 classes: with_mask, without_mask\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def prepare_data(self, batch_size=32):\n",
    "        \"\"\"Prepare training and validation data\"\"\"\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            zoom_range=0.2,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        \n",
    "        val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            os.path.join(self.data_dir, 'train'),\n",
    "            target_size=self.img_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        val_generator = val_datagen.flow_from_directory(\n",
    "            os.path.join(self.data_dir, 'validation'),\n",
    "            target_size=self.img_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        return train_generator, val_generator\n",
    "    \n",
    "    def train(self, epochs=10, batch_size=32):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        if self.model is None:\n",
    "            self.create_model()\n",
    "        \n",
    "        train_gen, val_gen = self.prepare_data(batch_size)\n",
    "        \n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=3,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=2,\n",
    "                min_lr=1e-7\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def save_model(self, path='mask_detector_model.h5'):\n",
    "        \"\"\"Save the trained model\"\"\"\n",
    "        if self.model:\n",
    "            self.model.save(path)\n",
    "            print(f\"Model saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDetector:\n",
    "    def __init__(self, model_path='mask_detector_model.h5'):\n",
    "        \"\"\"Initialize the detector\"\"\"\n",
    "        self.model = keras.models.load_model(model_path)\n",
    "        self.face_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "        )\n",
    "        self.classes = ['with_mask', 'without_mask']\n",
    "        self.colors = {\n",
    "            'with_mask': (0, 255, 0),      # Green\n",
    "            'without_mask': (0, 0, 255)    # Red\n",
    "        }\n",
    "    \n",
    "    def detect_and_predict(self, frame):\n",
    "        \"\"\"Detect faces and predict mask status\"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(\n",
    "            gray, \n",
    "            scaleFactor=1.1, \n",
    "            minNeighbors=5, \n",
    "            minSize=(60, 60)\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract face ROI\n",
    "            face_roi = frame[y:y+h, x:x+w]\n",
    "            face_resized = cv2.resize(face_roi, (224, 224))\n",
    "            face_array = np.expand_dims(face_resized / 255.0, axis=0)\n",
    "            \n",
    "            # Predict\n",
    "            predictions = self.model.predict(face_array, verbose=0)\n",
    "            class_idx = np.argmax(predictions[0])\n",
    "            confidence = predictions[0][class_idx]\n",
    "            label = self.classes[class_idx]\n",
    "            \n",
    "            results.append({\n",
    "                'bbox': (x, y, w, h),\n",
    "                'label': label,\n",
    "                'confidence': confidence\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def draw_predictions(self, frame, results):\n",
    "        \"\"\"Draw bounding boxes and labels on frame\"\"\"\n",
    "        for result in results:\n",
    "            x, y, w, h = result['bbox']\n",
    "            label = result['label']\n",
    "            confidence = result['confidence']\n",
    "            color = self.colors[label]\n",
    "            \n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            \n",
    "            # Draw label with confidence\n",
    "            text = f\"{label}: {confidence*100:.1f}%\"\n",
    "            cv2.putText(\n",
    "                frame, text, (x, y-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2\n",
    "            )\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def run_webcam(self):\n",
    "        \"\"\"Run real-time detection on webcam\"\"\"\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        print(\"Press 'q' to quit\")\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Detect and predict\n",
    "            results = self.detect_and_predict(frame)\n",
    "            \n",
    "            # Draw results\n",
    "            frame = self.draw_predictions(frame, results)\n",
    "            \n",
    "            # Display\n",
    "            cv2.imshow('Face Mask Detection', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def process_image(self, image_path):\n",
    "        \"\"\"Process a single image\"\"\"\n",
    "        frame = cv2.imread(image_path)\n",
    "        results = self.detect_and_predict(frame)\n",
    "        frame = self.draw_predictions(frame, results)\n",
    "        \n",
    "        cv2.imshow('Result', frame)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb6781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # TRAINING (Run this first with your dataset)\n",
    "\n",
    "    trainer = MaskDetectionTrainer(data_dir='C:\\\\Users\\\\LENOVO\\\\OneDrive - King Salman International University\\\\Desktop\\\\dataset')\n",
    "    trainer.create_model()\n",
    "    history = trainer.train(epochs=15)\n",
    "    trainer.save_model('mask_detector_model.h5')\n",
    "    \n",
    "    \n",
    "    # REAL-TIME DETECTION (Run this after training)\n",
    "    \n",
    "    detector = MaskDetector(model_path='mask_detector_model.h5')\n",
    "    detector.run_webcam()  # For webcam\n",
    "    # OR \n",
    "    detector.process_image('path/to/image.jpg')  # For single image\n",
    "    \n",
    "    \n",
    "    print(\"Face Mask Detection System Ready!\")\n",
    "    print(\"\\nTo use:\")\n",
    "    print(\"1. Organize your dataset in the required structure\")\n",
    "    print(\"2. Train the model using MaskDetectionTrainer\")\n",
    "    print(\"3. Run detection using MaskDetector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ece4ddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit\n"
     ]
    }
   ],
   "source": [
    "    detector = MaskDetector(model_path='mask_detector_model.h5')\n",
    "    detector.run_webcam()  # For webcam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
